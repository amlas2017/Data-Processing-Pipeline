---> Lancer PySpark avec SparkSession:

import pyspark
from pyspark.sql import SQLContext, SparkSession
from pyspark import SQLContext

# Setup the Configuration
conf = pyspark.SparkConf()

spark = SparkSession.builder.config(conf=conf).getOrCreate()
sqlcontext = SQLContext(spark)


=========================================================================================================================================================================

TP Spark ----->   https://insatunisia.github.io/TP-BigData/tp2/

--->  Cours référence Spark (français)  ---> http://b3d.bdpedia.fr/spark-batch.html

---> What is SparkSession
SparkSession introduced in version Spark 2.0, It is an entry point to underlying Spark functionality in order to programmatically create Spark RDD, DataFrame and DataSet.
SparkSession’s object spark is default available in spark-shell and it can be created programmatically using SparkSession builder pattern.

---> Spark Session also includes all the APIs available in different contexts:
      Spark Context,
      SQL Context,
      Streaming Context,
      Hive Context.

==========================================================Lancer Spark Job avec Mysql dans un cluster AWS===============================================================================================================
   ------------->    https://www.youtube.com/watch?v=SpvMRarBXYA&list=PLcw5TTdQlsEBmYJ62aWNS6msW3A0qp4Wi&index=6
